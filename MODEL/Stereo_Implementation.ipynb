{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWTqoLj6bowC",
        "outputId": "6ea536fc-b903-45bc-cf2d-45bab27162f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCrmD-MSX-3f"
      },
      "source": [
        "#PHASE II"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d7sKkjc-U2sq"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from scipy.stats import pearsonr, spearmanr, kendalltau"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25DuLGdqVIiQ"
      },
      "outputs": [],
      "source": [
        "IMAGE_HEIGHT = 128\n",
        "IMAGE_WIDTH = 128\n",
        "CHANNELS = 3\n",
        "ssim_scores = pd.read_csv('/content/drive/MyDrive/metrics_scores_phase2.csv')\n",
        "ssim_scores = ssim_scores[['Image', 'SSIM_Score']]\n",
        "def load_dataset(base_path, ssim_scores):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for folder in os.listdir(base_path):\n",
        "        folder_path = os.path.join(base_path, folder)\n",
        "        if os.path.isdir(folder_path):\n",
        "            for file in os.listdir(folder_path):\n",
        "                if file.endswith('.bmp'):\n",
        "                    file_path = os.path.join(folder_path, file)\n",
        "                    img = load_img(file_path, target_size=(IMAGE_HEIGHT, IMAGE_WIDTH))\n",
        "                    img_array = img_to_array(img)\n",
        "                    images.append(img_array)\n",
        "                    if folder == 'Reference':\n",
        "                        labels.append(1.0)\n",
        "                    else:\n",
        "                        label = ssim_scores[ssim_scores['Image'] == file]['SSIM_Score'].values[0]\n",
        "                        labels.append(label)\n",
        "    return np.array(images), np.array(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "83d7y89LVWzb"
      },
      "outputs": [],
      "source": [
        "base_path = '/content/drive/MyDrive/Phase2/Stimuli/separate'\n",
        "images, labels = load_dataset(base_path, ssim_scores)\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(images, labels, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b6gN6VC9VZ74"
      },
      "outputs": [],
      "source": [
        "def split_images(images):\n",
        "    left_images = images[:, :, :IMAGE_WIDTH//2, :]\n",
        "    right_images = images[:, :, IMAGE_WIDTH//2:, :]\n",
        "    return left_images, right_images\n",
        "train_left, train_right = split_images(train_images)\n",
        "test_left, test_right = split_images(test_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xy1Fz4pglmL8"
      },
      "outputs": [],
      "source": [
        "def build_feature_extractor(input_shape):\n",
        "    input_layer = tf.keras.Input(shape=input_shape)\n",
        "\n",
        "    x = layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same')(input_layer)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling2D((2, 2))(x)\n",
        "    x = layers.Dropout(0.1)(x)\n",
        "\n",
        "    x = layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling2D((2, 2))(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "\n",
        "    x = layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling2D((2, 2))(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "\n",
        "    x = layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling2D((2, 2))(x)\n",
        "    x = layers.Dropout(0.4)(x)\n",
        "\n",
        "    x = layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling2D((2, 2))(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(128, activation='relu', kernel_initializer='he_uniform')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "\n",
        "    return tf.keras.Model(inputs=input_layer, outputs=x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DbPjG5YXVoUM"
      },
      "outputs": [],
      "source": [
        "left_feature_extractor = build_feature_extractor(input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH // 2, CHANNELS))\n",
        "right_feature_extractor = build_feature_extractor(input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH // 2, CHANNELS))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "02quKvVEVqqX"
      },
      "outputs": [],
      "source": [
        "def build_combined_model(left_feature_extractor, right_feature_extractor, input_shape):\n",
        "    left_input = tf.keras.Input(shape=input_shape)\n",
        "    right_input = tf.keras.Input(shape=input_shape)\n",
        "\n",
        "    left_features = left_feature_extractor(left_input)\n",
        "    right_features = right_feature_extractor(right_input)\n",
        "\n",
        "    combined_features = layers.concatenate([left_features, right_features])\n",
        "    combined_features = layers.Dense(512, activation='relu')(combined_features)\n",
        "    combined_features = layers.BatchNormalization()(combined_features)\n",
        "    combined_features = layers.Dropout(0.5)(combined_features)\n",
        "\n",
        "    combined_features = layers.Dense(128, activation='relu')(combined_features)\n",
        "    combined_features = layers.BatchNormalization()(combined_features)\n",
        "    combined_features = layers.Dropout(0.5)(combined_features)\n",
        "\n",
        "    output = layers.Dense(1)(combined_features)\n",
        "\n",
        "    model = tf.keras.Model(inputs=[left_input, right_input], outputs=output)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxQsrRSSVvaO",
        "outputId": "082117f0-edfa-4e50-aa13-398f6c0e53a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)        [(None, 128, 64, 3)]         0         []                            \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)        [(None, 128, 64, 3)]         0         []                            \n",
            "                                                                                                  \n",
            " model (Functional)          (None, 128)                  1012896   ['input_3[0][0]']             \n",
            "                                                                                                  \n",
            " model_1 (Functional)        (None, 128)                  1012896   ['input_4[0][0]']             \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 256)                  0         ['model[0][0]',               \n",
            "                                                                     'model_1[0][0]']             \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 512)                  131584    ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_22 (Ba  (None, 512)                  2048      ['dense_2[0][0]']             \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " dropout_12 (Dropout)        (None, 512)                  0         ['batch_normalization_22[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dense_3 (Dense)             (None, 128)                  65664     ['dropout_12[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_23 (Ba  (None, 128)                  512       ['dense_3[0][0]']             \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " dropout_13 (Dropout)        (None, 128)                  0         ['batch_normalization_23[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dense_4 (Dense)             (None, 1)                    129       ['dropout_13[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2225729 (8.49 MB)\n",
            "Trainable params: 2220097 (8.47 MB)\n",
            "Non-trainable params: 5632 (22.00 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "combined_model = build_combined_model(left_feature_extractor, right_feature_extractor, (IMAGE_HEIGHT, IMAGE_WIDTH // 2, CHANNELS))\n",
        "combined_model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "combined_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U68eCeZpVzn3"
      },
      "outputs": [],
      "source": [
        "def regression_accuracy(y_true, y_pred):\n",
        "    return tf.keras.metrics.mean_absolute_percentage_error(y_true, y_pred)\n",
        "\n",
        "def plcc(y_true, y_pred):\n",
        "    y_true = tf.reshape(y_true, [-1])\n",
        "    y_pred = tf.reshape(y_pred, [-1])\n",
        "    return tf.py_function(func=lambda y_true, y_pred: np.float32(pearsonr(y_true, y_pred)[0]), inp=[y_true, y_pred], Tout=tf.float32)\n",
        "\n",
        "def srocc(y_true, y_pred):\n",
        "    y_true = tf.reshape(y_true, [-1])\n",
        "    y_pred = tf.reshape(y_pred, [-1])\n",
        "    return tf.py_function(func=lambda y_true, y_pred: np.float32(spearmanr(y_true, y_pred)[0]), inp=[y_true, y_pred], Tout=tf.float32)\n",
        "\n",
        "def rmse(y_true, y_pred):\n",
        "    return tf.sqrt(tf.keras.losses.mean_squared_error(y_true, y_pred))\n",
        "\n",
        "def krocc(y_true, y_pred):\n",
        "    y_true = tf.reshape(y_true, [-1])\n",
        "    y_pred = tf.reshape(y_pred, [-1])\n",
        "    return tf.py_function(func=lambda y_true, y_pred: np.float32(kendalltau(y_true, y_pred)[0]), inp=[y_true, y_pred], Tout=tf.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnGL1sll5CHf",
        "outputId": "0f317270-9a42-4941-bc47-159148657c96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "10/10 [==============================] - 57s 5s/step - loss: 0.1629 - mae: 0.3069 - val_loss: 0.0288 - val_mae: 0.1410\n",
            "Epoch 2/30\n",
            "10/10 [==============================] - 54s 6s/step - loss: 0.1510 - mae: 0.2939 - val_loss: 0.0288 - val_mae: 0.1415\n",
            "Epoch 3/30\n",
            "10/10 [==============================] - 53s 5s/step - loss: 0.1334 - mae: 0.2931 - val_loss: 0.0293 - val_mae: 0.1430\n",
            "Epoch 4/30\n",
            "10/10 [==============================] - 54s 5s/step - loss: 0.1598 - mae: 0.2892 - val_loss: 0.0254 - val_mae: 0.1328\n",
            "Epoch 5/30\n",
            "10/10 [==============================] - 50s 5s/step - loss: 0.1294 - mae: 0.2775 - val_loss: 0.0241 - val_mae: 0.1286\n",
            "Epoch 6/30\n",
            "10/10 [==============================] - 50s 5s/step - loss: 0.1359 - mae: 0.2904 - val_loss: 0.0249 - val_mae: 0.1308\n",
            "Epoch 7/30\n",
            "10/10 [==============================] - 50s 5s/step - loss: 0.1261 - mae: 0.2777 - val_loss: 0.0236 - val_mae: 0.1262\n",
            "Epoch 8/30\n",
            "10/10 [==============================] - 50s 5s/step - loss: 0.1141 - mae: 0.2560 - val_loss: 0.0209 - val_mae: 0.1194\n",
            "Epoch 9/30\n",
            "10/10 [==============================] - 53s 5s/step - loss: 0.0831 - mae: 0.2243 - val_loss: 0.0203 - val_mae: 0.1170\n",
            "Epoch 10/30\n",
            "10/10 [==============================] - 50s 5s/step - loss: 0.1109 - mae: 0.2555 - val_loss: 0.0203 - val_mae: 0.1171\n",
            "Epoch 11/30\n",
            "10/10 [==============================] - 50s 5s/step - loss: 0.1126 - mae: 0.2523 - val_loss: 0.0216 - val_mae: 0.1202\n",
            "Epoch 12/30\n",
            "10/10 [==============================] - 50s 5s/step - loss: 0.0928 - mae: 0.2345 - val_loss: 0.0216 - val_mae: 0.1197\n",
            "Epoch 13/30\n",
            "10/10 [==============================] - 50s 5s/step - loss: 0.0934 - mae: 0.2349 - val_loss: 0.0205 - val_mae: 0.1166\n",
            "Epoch 14/30\n",
            "10/10 [==============================] - 57s 6s/step - loss: 0.0947 - mae: 0.2338 - val_loss: 0.0214 - val_mae: 0.1187\n",
            "Epoch 15/30\n",
            "10/10 [==============================] - 50s 5s/step - loss: 0.1039 - mae: 0.2448 - val_loss: 0.0211 - val_mae: 0.1178\n",
            "Epoch 16/30\n",
            "10/10 [==============================] - 50s 5s/step - loss: 0.0908 - mae: 0.2386 - val_loss: 0.0199 - val_mae: 0.1158\n",
            "Epoch 17/30\n",
            "10/10 [==============================] - 50s 5s/step - loss: 0.0854 - mae: 0.2296 - val_loss: 0.0200 - val_mae: 0.1154\n",
            "Epoch 18/30\n",
            "10/10 [==============================] - 52s 5s/step - loss: 0.0817 - mae: 0.2189 - val_loss: 0.0194 - val_mae: 0.1143\n",
            "Epoch 19/30\n",
            "10/10 [==============================] - 53s 5s/step - loss: 0.0814 - mae: 0.2166 - val_loss: 0.0199 - val_mae: 0.1154\n",
            "Epoch 20/30\n",
            "10/10 [==============================] - 50s 5s/step - loss: 0.0677 - mae: 0.2094 - val_loss: 0.0203 - val_mae: 0.1162\n",
            "Epoch 21/30\n",
            "10/10 [==============================] - 50s 5s/step - loss: 0.0838 - mae: 0.2151 - val_loss: 0.0194 - val_mae: 0.1151\n",
            "Epoch 22/30\n",
            "10/10 [==============================] - 53s 5s/step - loss: 0.0855 - mae: 0.2270 - val_loss: 0.0194 - val_mae: 0.1155\n",
            "Epoch 23/30\n",
            "10/10 [==============================] - 50s 5s/step - loss: 0.0741 - mae: 0.2036 - val_loss: 0.0192 - val_mae: 0.1147\n",
            "Epoch 24/30\n",
            "10/10 [==============================] - 50s 5s/step - loss: 0.0794 - mae: 0.2206 - val_loss: 0.0190 - val_mae: 0.1138\n",
            "Epoch 25/30\n",
            "10/10 [==============================] - 50s 5s/step - loss: 0.0670 - mae: 0.2058 - val_loss: 0.0186 - val_mae: 0.1131\n",
            "Epoch 26/30\n",
            "10/10 [==============================] - 50s 5s/step - loss: 0.0702 - mae: 0.2040 - val_loss: 0.0186 - val_mae: 0.1131\n",
            "Epoch 27/30\n",
            "10/10 [==============================] - 52s 5s/step - loss: 0.0662 - mae: 0.2031 - val_loss: 0.0186 - val_mae: 0.1133\n",
            "Epoch 28/30\n",
            "10/10 [==============================] - 50s 5s/step - loss: 0.0765 - mae: 0.1999 - val_loss: 0.0188 - val_mae: 0.1135\n",
            "Epoch 29/30\n",
            "10/10 [==============================] - 50s 5s/step - loss: 0.0708 - mae: 0.2022 - val_loss: 0.0190 - val_mae: 0.1138\n",
            "Epoch 30/30\n",
            "10/10 [==============================] - 50s 5s/step - loss: 0.0610 - mae: 0.1932 - val_loss: 0.0187 - val_mae: 0.1123\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "history = combined_model.fit(\n",
        "    [train_left, train_right],\n",
        "    train_labels,\n",
        "    epochs=30,\n",
        "    batch_size=32,\n",
        "    validation_data=([test_left, test_right], test_labels)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1S26SI-5CkK",
        "outputId": "206051f5-6f60-4d8f-a312-dc0b6e0630b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 4s 1s/step - loss: 0.0187 - mae: 0.1123\n",
            "\n",
            "Evaluation Metrics:\n",
            "MSE: 0.018688136711716652\n",
            "MAE: 0.11228048801422119\n"
          ]
        }
      ],
      "source": [
        "metrics = combined_model.evaluate([test_left, test_right], test_labels, verbose=1)\n",
        "print(\"\\nEvaluation Metrics:\")\n",
        "print(f\"MSE: {metrics[0]}\")\n",
        "print(f\"MAE: {metrics[1]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A72gEZQmCI0l",
        "outputId": "02f2228e-f00c-4159-ce63-8908c6723c05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 9s 1s/step - loss: 0.0187 - regression_accuracy: 15.1799 - plcc: 0.4710 - srocc: 0.4522 - rmse: 0.1123 - krocc: 0.3125\n",
            "\n",
            "Evaluation Metrics:\n",
            "MSE: 0.018688136711716652\n",
            "Reg. Accuracy: 15.179885864257812\n",
            "PLCC: 0.4709664285182953\n",
            "SROCC: 0.4522044360637665\n",
            "RMSE: 0.11228048801422119\n",
            "KROCC: 0.31247952580451965\n"
          ]
        }
      ],
      "source": [
        "combined_model.compile(optimizer='adam', loss='mse', metrics=[regression_accuracy, plcc, srocc, rmse, krocc])\n",
        "metrics = combined_model.evaluate([test_left, test_right], test_labels, verbose=1)\n",
        "print(\"\\nEvaluation Metrics:\")\n",
        "print(f\"MSE: {metrics[0]}\")\n",
        "print(f\"Reg. Accuracy: {metrics[1]}\")\n",
        "print(f\"PLCC: {metrics[2]}\")\n",
        "print(f\"SROCC: {metrics[3]}\")\n",
        "print(f\"RMSE: {metrics[4]}\")\n",
        "print(f\"KROCC: {metrics[5]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "moKwXyxUCM7q",
        "outputId": "2219ef10-504a-413d-aef3-b6880d8682e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Metrics for Fast_Fading:\n",
            "MSE: 0.012053858488798141\n",
            "PLCC: 0.7916707396507263\n",
            "SROCC: 0.8249080777168274\n",
            "RMSE: 0.08888654410839081\n",
            "KROCC: 0.6993088126182556\n",
            "\n",
            "Metrics for Gaussian_Blur:\n",
            "MSE: 0.01767377182841301\n",
            "PLCC: 0.7155044078826904\n",
            "SROCC: 0.7164444327354431\n",
            "RMSE: 0.112137570977211\n",
            "KROCC: 0.5449308753013611\n",
            "\n",
            "Metrics for JPEG:\n",
            "MSE: 0.006941850762814283\n",
            "PLCC: 0.4848615229129791\n",
            "SROCC: 0.4461331367492676\n",
            "RMSE: 0.06817054003477097\n",
            "KROCC: 0.3408524990081787\n",
            "\n",
            "Metrics for JPEG_2000:\n",
            "MSE: 0.008008809760212898\n",
            "PLCC: 0.6253728270530701\n",
            "SROCC: 0.6444514393806458\n",
            "RMSE: 0.07522796839475632\n",
            "KROCC: 0.5213133692741394\n",
            "\n",
            "Metrics for White_Noise:\n",
            "MSE: 0.023903507739305496\n",
            "PLCC: 0.7056638598442078\n",
            "SROCC: 0.6147651672363281\n",
            "RMSE: 0.12798111140727997\n",
            "KROCC: 0.4890553057193756\n",
            "3/3 [==============================] - 5s 1s/step - loss: 0.0187 - regression_accuracy: 15.1799 - plcc: 0.4710 - srocc: 0.4522 - rmse: 0.1123 - krocc: 0.3125\n"
          ]
        }
      ],
      "source": [
        "distortion_types = ['Fast_Fading', 'Gaussian_Blur', 'JPEG', 'JPEG_2000', 'White_Noise']\n",
        "metrics_per_distortion = {distortion_type: {} for distortion_type in distortion_types}\n",
        "\n",
        "for distortion_type in distortion_types:\n",
        "    distortion_folder = os.path.join(base_path, distortion_type)\n",
        "    images = []\n",
        "    labels = []\n",
        "    for file in os.listdir(distortion_folder):\n",
        "        if file.endswith('.bmp'):\n",
        "            file_path = os.path.join(distortion_folder, file)\n",
        "            img = load_img(file_path, target_size=(IMAGE_HEIGHT, IMAGE_WIDTH))\n",
        "            img_array = img_to_array(img)\n",
        "            images.append(img_array)\n",
        "\n",
        "            if distortion_type == 'Reference':\n",
        "                labels.append(1.0)\n",
        "            else:\n",
        "                label = ssim_scores[ssim_scores['Image'] == file]['SSIM_Score'].values[0]\n",
        "                labels.append(label)\n",
        "\n",
        "    images = np.array(images)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    left_images, right_images = split_images(images)\n",
        "\n",
        "    subset_metrics = combined_model.evaluate([left_images, right_images], labels, verbose=0)\n",
        "\n",
        "    metrics_per_distortion[distortion_type]['MSE'] = subset_metrics[0]\n",
        "    metrics_per_distortion[distortion_type]['PLCC'] = subset_metrics[2]\n",
        "    metrics_per_distortion[distortion_type]['SROCC'] = subset_metrics[3]\n",
        "    metrics_per_distortion[distortion_type]['RMSE'] = subset_metrics[4]\n",
        "    metrics_per_distortion[distortion_type]['KROCC'] = subset_metrics[5]\n",
        "for distortion_type, metrics in metrics_per_distortion.items():\n",
        "    print(f\"\\nMetrics for {distortion_type}:\")\n",
        "    print(f\"MSE: {metrics['MSE']}\")\n",
        "    print(f\"PLCC: {metrics['PLCC']}\")\n",
        "    print(f\"SROCC: {metrics['SROCC']}\")\n",
        "    print(f\"RMSE: {metrics['RMSE']}\")\n",
        "    print(f\"KROCC: {metrics['KROCC']}\")\n",
        "metrics = combined_model.evaluate([test_left, test_right], test_labels, verbose=1)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}